{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf798513",
   "metadata": {
    "id": "cf798513"
   },
   "source": [
    "# CISC/CMPE 452/COGS 400 Assignment 3 - Unsupervised Learning (10 points)  \n",
    "\n",
    "Please put your name and student id\n",
    "\n",
    "    FirstName LastName, #12345678\n",
    "\n",
    "- The notebook file has clearly marked blocks where you are expected to write code. Do not write or modify any code outside of these blocks.\n",
    "- Make sure to run all the cells from the beginning before submission. Do not clear out the outputs. You will only get credit for code that has been run.\n",
    "- Mark will be deducted based on late policy (-1% of the course total marks per day after due date until the end date after which no assignments will be accepted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VRLNrFDU3dKp",
   "metadata": {
    "id": "VRLNrFDU3dKp"
   },
   "source": [
    "## Dataset\n",
    "The dataset is [Palmer Archipelago (Antarctica) penguin data](https://www.kaggle.com/datasets/parulpandey/palmer-archipelago-antarctica-penguin-data)  \n",
    "The dataset has 6 features and 1 label called species (Chinstrap, Adélie, or Gentoo)  \n",
    "The dataset is preprocessed into x_train, x_test, y_train, y_test  \n",
    "\n",
    "## Part 1 Kohonen Learning and MaxNet (5 points)\n",
    "- Build a Kohonen network (Kohonen-1) with Maxnet to cluster the preprocessed data (3 points)  \n",
    "- Train the model with both train and test sets (1 point)  \n",
    "- Print the confusion matrix of the predicted results (1 point)  \n",
    "\n",
    "## Part 2 Principle Component Analysis Network (5 points)\n",
    "- Build a PCA network to reduce the number of input features from 6 to 4 (2 points)  \n",
    "- Build a Kohonen network (Kohonen-2) with Maxnet to cluster the data  \n",
    "- Train the model with the new train and test sets generated by PCA network (1 point)  \n",
    "- Print the confusion matrix of the predicted results (1 point)  \n",
    "- Compare the predicted results with Kohonen-1 and analyze the results (1 point)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "365c1658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.6.1-cp39-cp39-macosx_10_12_x86_64.whl (7.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.3 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/donghao/Library/Python/3.9/lib/python/site-packages (from matplotlib) (21.3)\n",
      "Collecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.2.0-cp39-cp39-macosx_10_10_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 12.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.37.4-py3-none-any.whl (960 kB)\n",
      "\u001b[K     |████████████████████████████████| 960 kB 12.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp39-cp39-macosx_10_9_x86_64.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 6.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /Users/donghao/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.0.9)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.0.5-cp39-cp39-macosx_10_9_x86_64.whl (241 kB)\n",
      "\u001b[K     |████████████████████████████████| 241 kB 12.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/donghao/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.19 in /Users/donghao/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Installing collected packages: pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[33m  WARNING: The scripts fonttools, pyftmerge, pyftsubset and ttx are installed in '/Users/donghao/Library/Python/3.9/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed contourpy-1.0.5 cycler-0.11.0 fonttools-4.37.4 kiwisolver-1.4.4 matplotlib-3.6.1 pillow-9.2.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 22.3 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7e6a263",
   "metadata": {
    "id": "b7e6a263"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cbd2a73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "8cbd2a73",
    "outputId": "6192817d-46db-4c02-8dc7-12dbaf46fd6b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen              39.1             18.7              181.0   \n",
       "1  Adelie  Torgersen              39.5             17.4              186.0   \n",
       "2  Adelie  Torgersen              40.3             18.0              195.0   \n",
       "3  Adelie  Torgersen               NaN              NaN                NaN   \n",
       "4  Adelie  Torgersen              36.7             19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    MALE  \n",
       "1       3800.0  FEMALE  \n",
       "2       3250.0  FEMALE  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  FEMALE  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "data = pd.read_csv('data/penguins_size.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbca53b",
   "metadata": {
    "id": "bcbca53b"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e2314c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "7e2314c0",
    "outputId": "9f4ab080-1ca6-4831-bd43-aaad0c7c19b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   species  island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0        0       2              39.1             18.7              181.0   \n",
       "1        0       2              39.5             17.4              186.0   \n",
       "2        0       2              40.3             18.0              195.0   \n",
       "4        0       2              36.7             19.3              193.0   \n",
       "5        0       2              39.3             20.6              190.0   \n",
       "\n",
       "   body_mass_g  sex  \n",
       "0       3750.0  0.0  \n",
       "1       3800.0  1.0  \n",
       "2       3250.0  1.0  \n",
       "4       3450.0  1.0  \n",
       "5       3650.0  0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna()\n",
    "data = data[data['sex'] != '.']\n",
    "\n",
    "cleanup_nums = {\"species\": {\"Adelie\": 0, \"Chinstrap\": 1, \"Gentoo\": 2},\n",
    "                \"island\": {\"Biscoe\": 0, \"Dream\": 1, \"Torgersen\": 2},\n",
    "                \"sex\": {\"MALE\": 0.0, \"FEMALE\": 1.0}}\n",
    "data = data.replace(cleanup_nums)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c66e5cd1",
   "metadata": {
    "id": "c66e5cd1"
   },
   "outputs": [],
   "source": [
    "x = np.array(data.drop(['species'], axis=1).copy())\n",
    "x = (x - x.mean(axis=0)) / x.std(axis=0) # data normalization\n",
    "y = np.array(data['species'].copy()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06c93a78",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "06c93a78",
    "outputId": "ecec22da-903c-4852-fd16-4853082d1051"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((266, 6), (67, 6), (266,), (67,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d236745e",
   "metadata": {
    "id": "d236745e"
   },
   "outputs": [],
   "source": [
    "# calculate the confusion matrix\n",
    "def evaluator(y, y_pred):    \n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    print('Confusion matrix:\\n', confusion_matrix(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cacb4f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cacb4f0",
    "outputId": "37656c5a-a727-41de-9711-88649f52d1fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[ 47   0  60]\n",
      " [ 26   0  32]\n",
      " [  0 101   0]]\n",
      "Confusion matrix:\n",
      " [[26  0 13]\n",
      " [ 8  0  2]\n",
      " [ 0 18  0]]\n"
     ]
    }
   ],
   "source": [
    "# setup a baseline model\n",
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters=3) # n_clusters - the number of clusters\n",
    "km.fit(x_train)\n",
    "y_pred = km.predict(x_train)\n",
    "evaluator(y_train, y_pred)\n",
    "y_pred = km.predict(x_test)\n",
    "evaluator(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thb94HziClZH",
   "metadata": {
    "id": "thb94HziClZH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e4a6b06",
   "metadata": {
    "id": "4e4a6b06"
   },
   "source": [
    "### Part 1 K-Means Clustering\n",
    "\n",
    "> Indented block\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29d82a53",
   "metadata": {
    "id": "29d82a53"
   },
   "outputs": [],
   "source": [
    "class Model1(object):\n",
    "    def __init__(self):\n",
    "        self.history = {}\n",
    "        self.history['train_acc'] = []\n",
    "        self.history['test_acc'] = []\n",
    "    \n",
    "    def relu (self, x):\n",
    "        x[x < 0] = 0\n",
    "        return x\n",
    "        \n",
    "    def train(self, x, y, x_test, y_test, learning_rate=0.1, n_iters=10, verbose=True):\n",
    "        n_train, input_size = x.shape\n",
    "        output_size = len(np.unique(y))\n",
    "        n_test = x_test.shape[0]\n",
    "        self.W = np.ones((input_size, output_size))\n",
    "\n",
    "        for i in range(n_iters):\n",
    "#             if (i+1)%2 == 0:\n",
    "#                 learning_rate *= 0.5\n",
    "            for xi, yi in zip(x, y):\n",
    "                dist = self.relu(np.matmul(xi, self.W))\n",
    "                index = np.argmax(dist)\n",
    "                self.W[:, index] += learning_rate * (xi - self.W[:, index])\n",
    "            #print('epoch %d, learning rate %.4f' % (i + 1, learning_rate))\n",
    "        y_pred = self.predict(x)\n",
    "        evaluator(y, y_pred)\n",
    "        y_pred = self.predict(x_test)\n",
    "        evaluator(y_test, y_pred)\n",
    "\n",
    "    def predict(self, x):\n",
    "        y_pred = np.argmax(self.relu(np.matmul(x, self.W)), axis=1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f61079b4",
   "metadata": {
    "id": "f61079b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[ 51  56   0]\n",
      " [ 26  32   0]\n",
      " [  0   0 101]]\n",
      "Confusion matrix:\n",
      " [[27 12  0]\n",
      " [ 8  2  0]\n",
      " [ 0  0 18]]\n"
     ]
    }
   ],
   "source": [
    "# initialize and train Kohonen-1\n",
    "model1 = Model1()\n",
    "model1.train(x_train, y_train, x_test, y_test, learning_rate=0.001, n_iters=50, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8773264b",
   "metadata": {
    "id": "8773264b"
   },
   "outputs": [],
   "source": [
    "# print the confusion matrix of both train and test sets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c4c483",
   "metadata": {
    "id": "50c4c483"
   },
   "source": [
    "### Part 2 Principle Component Analysis Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "X-la8a6OCy3h",
   "metadata": {
    "id": "X-la8a6OCy3h"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b373ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv into Numpy array\n",
    "txtData = np.genfromtxt('data/sound.csv', delimiter=',')\n",
    "txtData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa421ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save array to WAV audio file\n",
    "scaledData = np.int16(txtData * 8000)\n",
    "wavfile.write('data/sound.wav', 8000, scaledData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bab346b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read waveform from audio file\n",
    "samrate, data = wavfile.read('data/sound.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "F9zbWZAQnkV3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9zbWZAQnkV3",
    "outputId": "df3b5032-fda9-4b24-d852-5a216c25e5d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, (50000, 2))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samrate, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "IG7WDg33pV1F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IG7WDg33pV1F",
    "outputId": "f1b2ec60-43a1-44d9-f417-8b95f67300aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7375, -7937],\n",
       "       [  312,  -562],\n",
       "       [ -187,   187],\n",
       "       ...,\n",
       "       [-2000,  2125],\n",
       "       [-1937,  2062],\n",
       "       [-1562,  1625]], dtype=int16)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "CVE9XcLIptt-",
   "metadata": {
    "id": "CVE9XcLIptt-"
   },
   "outputs": [],
   "source": [
    "data = data/8000\n",
    "# data = data * np.max(data) #(data - data.mean(axis=0)) / data.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "HuuL84Las3nV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HuuL84Las3nV",
    "outputId": "a441a574-7327-4d17-a810-246feaf15856"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.921875, -0.992125],\n",
       "       [ 0.039   , -0.07025 ],\n",
       "       [-0.023375,  0.023375],\n",
       "       ...,\n",
       "       [-0.25    ,  0.265625],\n",
       "       [-0.242125,  0.25775 ],\n",
       "       [-0.19525 ,  0.203125]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "uzumYEgmDLl1",
   "metadata": {
    "id": "uzumYEgmDLl1"
   },
   "outputs": [],
   "source": [
    "class PCA(object):\n",
    "    def __init__(self, lr=0.01, epoch=10):\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        \n",
    "    def train(self, x, n_components=1):\n",
    "        self.W = np.random.rand(x.shape[1], n_components)\n",
    "        for k in range(self.epoch):\n",
    "            for xi in x:\n",
    "                y = self.W[0] * xi[0] + self.W[1] * xi[1]\n",
    "                dW1 = self.lr * y * xi[0] - y ** 2 * self.W[0]\n",
    "                dW2 = self.lr * y * xi[1] - y ** 2 * self.W[1]\n",
    "                self.W[0] += dW1\n",
    "                self.W[1] += dW2\n",
    "        return\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.matmul(x, self.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "XRNqR80YDLiO",
   "metadata": {
    "id": "XRNqR80YDLiO"
   },
   "outputs": [],
   "source": [
    "pca = PCA(lr=1, epoch=2)\n",
    "pca.train(np.array(data), 1)\n",
    "x = pca.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "VcUvhXMuDLfC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VcUvhXMuDLfC",
    "outputId": "6f2d41bc-7871-42d3-9120-ee01cc3e3303"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3OpxZ7yODLcI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "3OpxZ7yODLcI",
    "outputId": "85c5f208-8939-4ad2-9ada-039156ecccda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.35429904],\n",
       "       [-0.07813589],\n",
       "       [ 0.03302665],\n",
       "       ...,\n",
       "       [ 0.36474254],\n",
       "       [ 0.35361591],\n",
       "       [ 0.28167391]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8LpMkEnuDLUU",
   "metadata": {
    "id": "8LpMkEnuDLUU"
   },
   "outputs": [],
   "source": [
    "scaledData = np.int16(x/np.max(np.abs(x))*8000)\n",
    "wavfile.write('data/output.wav', 8000, scaledData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SRIQv8XTDLJo",
   "metadata": {
    "id": "SRIQv8XTDLJo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4s5xpoDDK--",
   "metadata": {
    "id": "a4s5xpoDDK--"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
