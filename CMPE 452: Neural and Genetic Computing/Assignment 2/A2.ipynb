{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf798513",
   "metadata": {
    "id": "cf798513"
   },
   "source": [
    "# CISC/CMPE 452/COGS 400 Assignment 2 - Backpropagation (15 points)  \n",
    "\n",
    "Please put your name and student id here\n",
    "\n",
    "    Alex Perrin, 20056483\n",
    "\n",
    "- The notebook file has clearly marked blocks where you are expected to write code. Do not write or modify any code outside of these blocks.\n",
    "- Make sure to restart and run all the cells from the beginning before submission. Do not clear out the outputs. You will only get credit for code that has been run.\n",
    "- Mark will be deducted based on late policy (-1% of the course total marks per day after due date until the end date after which no assignments will be accepted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VRLNrFDU3dKp",
   "metadata": {
    "id": "VRLNrFDU3dKp"
   },
   "source": [
    "## [Part 1 (9 points)](#Part-1)  \n",
    "\n",
    "### Build Model1 (7 points)  \n",
    "Use Pytorch to implement a three-layer Neural Network (input layer - hidden layer - output layer) and update the weights with backpropagation  \n",
    "- 1. Implement forward and calculate the output (1 point)  \n",
    "- 2. Calculate errors and loss (3 points)  \n",
    "- 3. Update the weights with backpropagation (1 points)  \n",
    "- 4. Predict function (1 point)  \n",
    "- 5. Activation function (Sigmoid function) (1 point)  \n",
    "\n",
    "### Evaluator Function (1 point)  \n",
    "Implement the evaluator function with Pytorch or Numpy only   \n",
    "- Evaluation metrics include confusion matrix, accuracy, recall score, precision and F1 score\n",
    "\n",
    "### Train and Evaluate Model1 (1 point)  \n",
    "Train Model1 with customized hidden size, learning rate, number of iterations and batch size  \n",
    "Use the predict function to predict the labels with the test dataset  \n",
    "Evaluate the prediction results  \n",
    "- Evaluation metrics include confusion matrix, accuracy, recall score, precision and F1 score\n",
    "\n",
    "## [Part 2 (6 points)](#Part-2)  \n",
    "\n",
    "Use another machine learning framework (**scikit-learn, Tensorflow and Pytorch**) to build MLP\n",
    "e.g. \n",
    "  1. https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "  2. https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
    "  3. https://pytorch.org/tutorials/beginner/examples_nn/polynomial_nn.html#sphx-glr-beginner-examples-nn-polynomial-nn-py\n",
    "  \n",
    "### Build Model2-1 (2 points)  \n",
    "Implement Model2-1 with the same hidden nodes and optimization function as the model in Part 1  \n",
    "Train and validate model. Use the best model on validation dataset to test on the test dataset  \n",
    "\n",
    "### Train and Evaluate Model2-1 (1 point)\n",
    "Evaluate the prediction results  \n",
    "- Evaluation metrics include confusion matrix, accuracy, recall score, precision and F1 score\n",
    "\n",
    "### Build Model2-2 (2 points)  \n",
    "Add one more hidden layer (2 hidden layers in total) to the model  \n",
    "Describe Model2-2 (number of hidden nodes)  \n",
    "Train and validate model. Use the best model on validation dataset to test on the test dataset  \n",
    "\n",
    "### Train and Evaluate Model2-2 (1 point)\n",
    "Evaluate the prediction results  \n",
    "- Evaluation metrics include confusion matrix, accuracy, recall score, precision and F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7e6a263",
   "metadata": {
    "id": "b7e6a263"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eKE_KANU7_sq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eKE_KANU7_sq",
    "outputId": "946cd1ab-22bd-4efa-c734-faab97e6f40d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can go to Edit - Notebook settings to select GPU under the Hardware accelerator\n",
    "# check the device\n",
    "device = torch.device('cuda' if not torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a5cbc46",
   "metadata": {
    "id": "9a5cbc46"
   },
   "outputs": [],
   "source": [
    "# build the dataset (train, validation and test)\n",
    "def load_MNIST(n_val=10000, n_sample=1000, sample=False):\n",
    "    n_val = n_val\n",
    "    n_sample = n_sample\n",
    "    train = MNIST(root = '.', train = True, download = True)\n",
    "    test = MNIST(root = '.', train = False, download = True)\n",
    "    \n",
    "    # data preprocessing\n",
    "    x_train, x_test = train.data/255, test.data/255\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "    y_train = torch.nn.functional.one_hot(train.targets)\n",
    "    y_test = torch.nn.functional.one_hot(test.targets)\n",
    "\n",
    "    data_dict = {}\n",
    "    if sample:\n",
    "        data_dict['x_train'] = x_train[:-n_val][:n_sample]\n",
    "        data_dict['y_train'] = y_train[:-n_val][:n_sample]\n",
    "        data_dict['x_val'] = x_train[-n_val:][:n_sample//10]\n",
    "        data_dict['y_val'] = y_train[-n_val:][:n_sample//10]\n",
    "        data_dict['x_test'] = x_test[:n_sample//10]\n",
    "        data_dict['y_test'] = y_test[:n_sample//10]\n",
    "    else:\n",
    "        data_dict['x_train'] = x_train[:-n_val]\n",
    "        data_dict['y_train'] = y_train[:-n_val]\n",
    "        data_dict['x_val'] = x_train[-n_val:]\n",
    "        data_dict['y_val'] = y_train[-n_val:]\n",
    "        data_dict['x_test'] = x_test\n",
    "        data_dict['y_test'] = y_test\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Q5G-vmpD21Bj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "Q5G-vmpD21Bj",
    "outputId": "f053f294-9aad-4097-f75e-aaed70dd050e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: torch.Size([50000, 784])\n",
      "Train labels shape: torch.Size([50000, 10])\n",
      "Validation data shape: torch.Size([10000, 784])\n",
      "Validation labels shape: torch.Size([10000, 10])\n",
      "Test data shape: torch.Size([10000, 784])\n",
      "Test labels shape: torch.Size([10000, 10])\n"
     ]
    }
   ],
   "source": [
    "# you can start with a small sample dataset by setting sample=True\n",
    "data_dict = load_MNIST(sample=False)\n",
    "print('Train data shape:', data_dict['x_train'].shape)\n",
    "print('Train labels shape:', data_dict['y_train'].shape)\n",
    "print('Validation data shape:', data_dict['x_val'].shape)\n",
    "print('Validation labels shape:', data_dict['y_val'].shape)\n",
    "print('Test data shape:', data_dict['x_test'].shape)\n",
    "print('Test labels shape:', data_dict['y_test'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1aa9f016",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "1aa9f016",
    "outputId": "83a4195e-8fb9-4850-8a9a-7c3bbc2bb623",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot an example\n",
    "plt.imshow(data_dict['x_train'][0].reshape(28, 28))\n",
    "plt.title(data_dict['y_train'][0].argmax().item())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6291c647",
   "metadata": {
    "id": "6291c647"
   },
   "outputs": [],
   "source": [
    "def evaluator(y_test, y_pred):\n",
    "    ####################################################################################################\n",
    "    # enter code here to implement the evaluation metrics including confusion matrix, accuracy, precision and recall\n",
    "    # you can only use Numpy or Pytorch to implement the metrics\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    for y_t,y_p in zip(y_test, y_pred):\n",
    "        if y_t==1 and y_p==1:\n",
    "            TP += 1\n",
    "        elif y_t==0 and y_p==0:\n",
    "            TN += 1\n",
    "        elif y_t==1 and y_p==0:\n",
    "            FN += 1\n",
    "        elif y_t==0 and y_p==1:\n",
    "            FP += 1\n",
    "\n",
    "    confusion_matrix = np.array([[TN,FP], [FN,TP]])\n",
    "    accuracy = (TP+TN)/(TP+TN+FP+FN)\n",
    "    percision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f1 = 2*percision*recall/(percision+recall)\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    for i in confusion_matrix:\n",
    "        print(i)\n",
    "    print(\"Accuracy: %.4f\" % accuracy)\n",
    "    print(\"Percision: %.4f\" % percision)\n",
    "    print(\"Recall: %.4f\" % recall)\n",
    "    print(\"F1: %.4f\" % f1)\n",
    "\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4a6b06",
   "metadata": {
    "id": "4e4a6b06"
   },
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0d3fc2d",
   "metadata": {
    "id": "a0d3fc2d"
   },
   "outputs": [],
   "source": [
    "class NN(object):\n",
    "    def __init__(self, learning_rate, n_iters, batch_size, hidden_size, device, dtype=torch.float32):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.batch_size = batch_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.history = {}\n",
    "        self.history['train_acc'], self.history['val_acc'], self.history['loss'] = [], [], []\n",
    "    \n",
    "    # 5. activation function\n",
    "    def sigmoid(self, x):\n",
    "        ####################################################################################################\n",
    "        # enter code here to implement the activation function\n",
    "        return 1/(1+np.exp(-x))\n",
    "        ####################################################################################################\n",
    "\n",
    "    def train(self, x, y, x_val, y_val, verbose=1):\n",
    "        n_train = x.shape[0]\n",
    "        n_val = x_val.shape[0]\n",
    "        input_size = x.shape[1]\n",
    "        num_classes = y.shape[1]\n",
    "        \n",
    "        # weight initialization\n",
    "        self.W1 = torch.randn(input_size, self.hidden_size, dtype=self.dtype, device=self.device) * 0.01\n",
    "        self.W2 = torch.randn(self.hidden_size, num_classes, dtype=self.dtype, device=self.device) * 0.01\n",
    "\n",
    "        # TODO: train the weights with the input data and labels\n",
    "        for i in range(self.n_iters):\n",
    "            loss = 0\n",
    "            data = getBatch(x, y, self.batch_size)\n",
    "            for x_batch, y_batch in data:\n",
    "                # 1. forward\n",
    "                ####################################################################################################\n",
    "                # enter code here to calculate the hidden layer output and output layer output\n",
    "                hidden = torch.tensor(torch.zeros(self.hidden_size),device=self.device)\n",
    "                for hidden_index in range(self.hidden_size):           \n",
    "                    a = torch.dot(x[i], torch.t(self.W1)[hidden_index])\n",
    "                    hidden[hidden_index] = self.sigmoid(a)\n",
    "\n",
    "                output = torch.tensor(torch.zeros(num_classes),device=self.device)\n",
    "                for output_index in range(num_classes):\n",
    "                    a = torch.dot(hidden, torch.t(self.W2)[output_index])\n",
    "                    output[output_index] = self.sigmoid(a)   \n",
    "                ####################################################################################################\n",
    "\n",
    "                # 2. error and loss\n",
    "                ####################################################################################################\n",
    "                # enter code here to calculate the output error, MSE loss, delta output and delta hidden\n",
    "                output_error = y_val[i]-output\n",
    "                loss += torch.sum(torch.square(output_error))\n",
    "\n",
    "                error_term_j = output_error*output*(1-output)\n",
    "                delta_output = self.learning_rate*error_term_j*output\n",
    "\n",
    "                error_term_h = torch.tensor(torch.zeros(self.hidden_size), device=self.device)\n",
    "                for i, w_jh in enumerate(self.W2):\n",
    "                    error_term_h[i] = torch.dot(error_term_j, w_jh)\n",
    "                delta_hidden = self.learning_rate*error_term_h*hidden                \n",
    "                ####################################################################################################\n",
    "\n",
    "                # 3. backward\n",
    "                ####################################################################################################\n",
    "                # enter code here to calculate delta weights and update the weights\n",
    "                self.W2 += delta_output\n",
    "                self.W1 += delta_hidden\n",
    "                \n",
    "                ####################################################################################################\n",
    "\n",
    "            # calculate the accuracy and save the training history\n",
    "            y_pred = self.predict(x)\n",
    "            train_acc = torch.sum(torch.argmax(y, dim=1) == y_pred) / n_train\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['loss'].append(loss)\n",
    "            \n",
    "            y_pred = self.predict(x_val)\n",
    "            val_acc = torch.sum(torch.argmax(y_val, dim=1) == y_pred) / n_val\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "            if verbose:\n",
    "                print('epoch %d, loss %.4f, train acc %.3f, validation acc %.3f'\n",
    "                  % (i + 1, loss, train_acc, val_acc))\n",
    "    \n",
    "    # 4. predict function \n",
    "    def predict(self, x):\n",
    "        ####################################################################################################\n",
    "        # enter code here to implement the predict function\n",
    "        # TODO: use the trained weights to predict labels and return the predicted labels\n",
    "        # remember to use torch.argmax() to return the true labels\n",
    "        hidden = torch.tensor(torch.zeros(self.hidden_size),device=self.device)\n",
    "        output = torch.tensor(torch.zeros(10),device=self.device)\n",
    "        y_pred = torch.tensor(torch.zeros(x.shape[0],10),device=self.device)\n",
    "        for i, xi in enumerate(x):\n",
    "            for hidden_index in range(self.hidden_size):           \n",
    "                a = torch.dot(xi, torch.t(self.W1)[hidden_index])\n",
    "                hidden[hidden_index] = self.sigmoid(a)\n",
    "            for output_index in range(10):\n",
    "                a = torch.dot(hidden, torch.t(self.W2)[output_index])\n",
    "                output[output_index] = self.sigmoid(a)\n",
    "            y_pred[i] = torch.argmax(output)\n",
    "\n",
    "        ####################################################################################################\n",
    "        return y_pred\n",
    "\n",
    "def getBatch(x, y, batch_size):\n",
    "    n_epoch = x.shape[0] // batch_size\n",
    "    for i in range(n_epoch):\n",
    "        x_batch = x[i * batch_size : (i+1) * batch_size]\n",
    "        y_batch = y[i * batch_size : (i+1) * batch_size]\n",
    "        yield x_batch, y_batch\n",
    "    x_batch = x[(i+1) * batch_size:]\n",
    "    y_batch = y[(i+1) * batch_size:]    \n",
    "    yield x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74e9819c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74e9819c",
    "outputId": "c6b1745f-4e19-4f83-afb7-c22f07062738"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-336e77a1db61>:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hidden = torch.tensor(torch.zeros(self.hidden_size),device=self.device)\n",
      "<ipython-input-15-336e77a1db61>:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = torch.tensor(torch.zeros(num_classes),device=self.device)\n",
      "<ipython-input-15-336e77a1db61>:57: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  error_term_h = torch.tensor(torch.zeros(self.hidden_size), device=self.device)\n",
      "<ipython-input-15-336e77a1db61>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hidden = torch.tensor(torch.zeros(self.hidden_size),device=self.device)\n",
      "<ipython-input-15-336e77a1db61>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = torch.tensor(torch.zeros(10),device=self.device)\n",
      "<ipython-input-15-336e77a1db61>:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_pred = torch.tensor(torch.zeros(x.shape[0],10),device=self.device)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (50000) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-fd824cb0de97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_test'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_test'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m####################################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-336e77a1db61>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x, y, x_val, y_val, verbose)\u001b[0m\n\u001b[0;32m     71\u001b[0m             \u001b[1;31m# calculate the accuracy and save the training history\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (50000) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "# enter code here to train Model1\n",
    "# TODO: set your desired hidden size, learning rate, number of iterations and batch size\n",
    "# remeber to load the dataset to the device (e.g. data_dict['x_train'].to(device))\n",
    "model1 = NN(0.1, 10, 1000, 16, device)\n",
    "data_dict['x_train'] = data_dict['x_train'].to(device)\n",
    "data_dict['y_train'] = data_dict['y_train'].to(device)\n",
    "data_dict['x_test'] = data_dict['x_test'].to(device)\n",
    "data_dict['y_test'] = data_dict['y_test'].to(device)\n",
    "model1.train(data_dict['x_train'], data_dict['y_train'], data_dict['x_test'], data_dict['y_test'])\n",
    "\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bebd0600",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "bebd0600",
    "outputId": "4cf59edb-b5bd-417c-913f-78b5a793189f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model1.history['train_acc'], label='train_acc')\n",
    "plt.plot(model1.history['val_acc'], label='val_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "UQciuqY96_6Z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQciuqY96_6Z",
    "outputId": "0aff8095-e7a6-4558-f99c-36d2512488f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-336e77a1db61>:90: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  hidden = torch.tensor(torch.zeros(self.hidden_size),device=self.device)\n",
      "<ipython-input-15-336e77a1db61>:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output = torch.tensor(torch.zeros(10),device=self.device)\n",
      "<ipython-input-15-336e77a1db61>:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_pred = torch.tensor(torch.zeros(x.shape[0],10),device=self.device)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-584e340e3458>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# enter code here to evaluate Model1 with test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# TODO: use the trained Model1 to predict the labels of test set and evaluate the results with the evaluator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mevaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_test'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m####################################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-cb4e29c754f6>\u001b[0m in \u001b[0;36mevaluator\u001b[1;34m(y_test, y_pred)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mFN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_p\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0mTP\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my_p\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "# enter code here to evaluate Model1 with test set\n",
    "# TODO: use the trained Model1 to predict the labels of test set and evaluate the results with the evaluator\n",
    "evaluator(data_dict['y_test'], model1.predict(data_dict['x_test']))\n",
    "\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bhkkGjWwxlLJ",
   "metadata": {
    "id": "bhkkGjWwxlLJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "QG_rb7uJ4XDL",
   "metadata": {
    "id": "QG_rb7uJ4XDL"
   },
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c845a9",
   "metadata": {},
   "source": [
    "### Model2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13519996",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# enter code here to implement Model2-1\n",
    "\n",
    "\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# enter code here to train Model2-1\n",
    "\n",
    "\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61594f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# enter code here to evaluate Model2-1\n",
    "\n",
    "\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a9243f",
   "metadata": {},
   "source": [
    "### Model2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf38a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# enter code here to implement Model2-2\n",
    "\n",
    "\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090300ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# enter code here to train Model2-2\n",
    "\n",
    "\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca87daf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################################################\n",
    "# enter code here to evaluate Model2-2\n",
    "\n",
    "\n",
    "####################################################################################################"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "A2_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "ba4c651cdc5ec17c511bce19f294202fdc45305f9de1f927c569f32faa173ead"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
